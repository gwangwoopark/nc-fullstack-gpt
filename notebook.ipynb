{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23ad07f",
   "metadata": {},
   "source": [
    "```shell\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and popular Indian dish - Chicken Tikka Masala. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons ground coriander\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon salt\n",
      "- 1 tablespoon vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated ginger\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, mix together the yogurt, lemon juice, cumin, coriander, turmeric, paprika, garam masala, and salt. Add the chicken pieces and coat them well with the marinade. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Preheat the oven to 400Â°F (200Â°C). Thread the marinated chicken pieces onto skewers and place them on a baking sheet. Bake for 20-25 minutes, or until the chicken is cooked through.\n",
      "\n",
      "3. In a large skillet, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute.\n",
      "\n",
      "4. Stir in the crushed tomatoes and simmer for 10 minutes. Add the heavy cream and cooked chicken tikka pieces. Simmer for an additional 5-10 minutes, stirring occasionally.\n",
      "\n",
      "5. Serve the Chicken Tikka Masala over steamed rice, garnished with fresh cilantro. Enjoy your delicious homemade Indian meal!\n",
      "\n",
      "Feel free to adjust the spice levels to suit your taste preferences. Enjoy your culinary journey into the flavors of India!For a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based alternative such as tofu or paneer. Here's how you can prepare these alternatives:\n",
      "\n",
      "1. **Tofu**: \n",
      "   - Use firm or extra firm tofu for this recipe.\n",
      "   - Drain the tofu and pat it dry with paper towels to remove excess moisture.\n",
      "   - Cut the tofu into bite-sized cubes and follow the marinade instructions as you would with the chicken. Tofu absorbs flavors well, so marinating it for a good amount of time will enhance its taste.\n",
      "   - Instead of baking, you can pan-fry the marinated tofu in a bit of oil until it's golden brown and slightly crispy.\n",
      "\n",
      "2. **Paneer**:\n",
      "   - Paneer is a type of Indian cheese that holds its shape well when cooked.\n",
      "   - Cut the paneer into cubes and follow the marinade instructions for the chicken.\n",
      "   - You can either bake the marinated paneer cubes in the oven or pan-fry them until they develop a golden crust.\n",
      "\n",
      "By using tofu or paneer as a substitute for chicken, you can still enjoy the rich flavors of Chicken Tikka Masala in a vegetarian-friendly way. Enjoy your meatless culinary adventure into Indian cuisine!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"For a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based alternative such as tofu or paneer. Here's how you can prepare these alternatives:\\n\\n1. **Tofu**: \\n   - Use firm or extra firm tofu for this recipe.\\n   - Drain the tofu and pat it dry with paper towels to remove excess moisture.\\n   - Cut the tofu into bite-sized cubes and follow the marinade instructions as you would with the chicken. Tofu absorbs flavors well, so marinating it for a good amount of time will enhance its taste.\\n   - Instead of baking, you can pan-fry the marinated tofu in a bit of oil until it's golden brown and slightly crispy.\\n\\n2. **Paneer**:\\n   - Paneer is a type of Indian cheese that holds its shape well when cooked.\\n   - Cut the paneer into cubes and follow the marinade instructions for the chicken.\\n   - You can either bake the marinated paneer cubes in the oven or pan-fry them until they develop a golden crust.\\n\\nBy using tofu or paneer as a substitute for chicken, you can still enjoy the rich flavors of Chicken Tikka Masala in a vegetarian-friendly way. Enjoy your meatless culinary adventure into Indian cuisine!\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "##\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "##\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "##\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\"cuisine\": \"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae697c0",
   "metadata": {},
   "source": [
    "### Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870d5610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event-driven, fast,\n",
      "JavaScript on server-side,\n",
      "Node.js, we code.ì´ í•´êµ¬ëŠ” 5-7-5 ì†Œì ˆ êµ¬ì¡°ë¥¼ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ì‹œì¸ì€ \"ì´ë²¤íŠ¸ ì¤‘ì‹¬, ë¹ ë¥¸,\" \"ì„œë²„ ì¸¡ ìë°”ìŠ¤í¬ë¦½íŠ¸,\" \"ë…¸ë“œ.js, ìš°ë¦¬ëŠ” ì½”ë”©\"ì´ë¼ëŠ” ë¬¸ì¥ì„ í†µí•´ Node.jsì˜ íŠ¹ì§•ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ í•´êµ¬ëŠ” ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìœ¼ë©°, ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ ì¸¡ í”„ë¡œê·¸ë˜ë°ì„ í•  ìˆ˜ ìˆëŠ” Node.jsì˜ íŠ¹ì§•ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \"ì´ë²¤íŠ¸ ì¤‘ì‹¬\"ê³¼ \"ë¹ ë¥¸\"ì´ë¼ëŠ” ë‹¨ì–´ëŠ” Node.jsì˜ ë¹„ë™ê¸°ì ì¸ íŠ¹ì„±ê³¼ ë†’ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ë©°, \"ìš°ë¦¬ëŠ” ì½”ë”©\"ì´ë¼ëŠ” ë¬¸êµ¬ëŠ” ê°œë°œìë“¤ì´ Node.jsë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë”©í•˜ëŠ” ê²½í—˜ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ í•´êµ¬ëŠ” ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆì§€ë§Œ, ê°„ê²°í•˜ê³  ëª…ë£Œí•œ í‘œí˜„ì„ í†µí•´ Node.jsì˜ ì¥ì ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ë©´ì„œë„ ì‹œì ì¸ ê°ì„±ì„ ë‹´ì•„ë‚´ê³  ìˆìŠµë‹ˆë‹¤."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='ì´ í•´êµ¬ëŠ” 5-7-5 ì†Œì ˆ êµ¬ì¡°ë¥¼ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ì‹œì¸ì€ \"ì´ë²¤íŠ¸ ì¤‘ì‹¬, ë¹ ë¥¸,\" \"ì„œë²„ ì¸¡ ìë°”ìŠ¤í¬ë¦½íŠ¸,\" \"ë…¸ë“œ.js, ìš°ë¦¬ëŠ” ì½”ë”©\"ì´ë¼ëŠ” ë¬¸ì¥ì„ í†µí•´ Node.jsì˜ íŠ¹ì§•ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nì´ í•´êµ¬ëŠ” ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìœ¼ë©°, ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ ì¸¡ í”„ë¡œê·¸ë˜ë°ì„ í•  ìˆ˜ ìˆëŠ” Node.jsì˜ íŠ¹ì§•ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \"ì´ë²¤íŠ¸ ì¤‘ì‹¬\"ê³¼ \"ë¹ ë¥¸\"ì´ë¼ëŠ” ë‹¨ì–´ëŠ” Node.jsì˜ ë¹„ë™ê¸°ì ì¸ íŠ¹ì„±ê³¼ ë†’ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ë©°, \"ìš°ë¦¬ëŠ” ì½”ë”©\"ì´ë¼ëŠ” ë¬¸êµ¬ëŠ” ê°œë°œìë“¤ì´ Node.jsë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë”©í•˜ëŠ” ê²½í—˜ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nì´ í•´êµ¬ëŠ” ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆì§€ë§Œ, ê°„ê²°í•˜ê³  ëª…ë£Œí•œ í‘œí˜„ì„ í†µí•´ Node.jsì˜ ì¥ì ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸°ìˆ ì ì¸ ì£¼ì œë¥¼ ë‹¤ë£¨ë©´ì„œë„ ì‹œì ì¸ ê°ì„±ì„ ë‹´ì•„ë‚´ê³  ìˆìŠµë‹ˆë‹¤.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "writing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are specialized in writing haikus about programming languages. Always generate responses in the form of a haiku (5-7-5 syllable structure) and ensure each haiku centers around themes of programming, coding languages, or software development. Be concise, creative, and poetic.\"),\n",
    "    (\"human\", \"{language}\"),\n",
    "])\n",
    "\n",
    "writing_chain = writing_prompt | chat \n",
    "\n",
    "reading_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are specialized in explaining haikus. When given a haiku, analyze its structure (syllable pattern, imagery, seasonal or thematic elements) and explain its meaning in a clear, thoughtful way in Korean. Focus on uncovering the poetic devices, cultural context, and emotional nuance. Be concise, insightful, and accessible to readers.\"),\n",
    "    (\"human\", \"{haiku}\"),\n",
    "])\n",
    "\n",
    "reading_chain = reading_prompt | chat\n",
    "\n",
    "final_chain = {\"haiku\": writing_chain} | reading_chain\n",
    "\n",
    "final_chain.invoke({\"language\": \"nodejs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf8ae6",
   "metadata": {},
   "source": [
    "### Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1713d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ ğŸ’°ğŸ”ª'\n",
      "content='ğŸš¢ğŸ’”ğŸ¶'\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"Top Gun\",\n",
    "        \"answer\": \"\"\"\n",
    "        ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"The Godfather\",\n",
    "        \"answer\": \"\"\"\n",
    "        ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{movie}\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie expert who provides three emojis to represent the movie.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{movie}?\"),\n",
    "])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert who provides three emojis to represent the movie.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"Parasite\")\n",
    "\n",
    "invoke_chain(\"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7867aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The movie you asked about first is \"Parasite.\"'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is the movie I asked first?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae29432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gwangwoopark/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gwangwoopark/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='According to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'\n",
      "content='He wrote \"2+2=5\" in the dust on the table.'\n",
      "content='Julia is a character in the text who was involved with the protagonist, Winston, in a forbidden relationship.'\n",
      "content=\"The first question you asked was about Aaronson's guilt.\"\n"
     ]
    }
   ],
   "source": [
    "# Assignment 4\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "def load_memory(_):\n",
    "    x = memory.load_memory_variables({})\n",
    "    return x[\"history\"]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"files/document.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer questions using only the following context and conversation history. If you don't know the answer, just say so. Don't make up an answer:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    { \n",
    "        \"context\": retriever, \n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": RunnableLambda(load_memory),\n",
    "    } \n",
    "    | prompt \n",
    "    | llm\n",
    ")\n",
    "    \n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"Is Aaronson guilty?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")\n",
    "invoke_chain(\"What is the first question I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5cf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
