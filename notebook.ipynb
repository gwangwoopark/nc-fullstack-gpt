{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23ad07f",
   "metadata": {},
   "source": [
    "```shell\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and popular Indian dish - Chicken Tikka Masala. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons ground coriander\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon salt\n",
      "- 1 tablespoon vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated ginger\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, mix together the yogurt, lemon juice, cumin, coriander, turmeric, paprika, garam masala, and salt. Add the chicken pieces and coat them well with the marinade. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated chicken pieces onto skewers and place them on a baking sheet. Bake for 20-25 minutes, or until the chicken is cooked through.\n",
      "\n",
      "3. In a large skillet, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute.\n",
      "\n",
      "4. Stir in the crushed tomatoes and simmer for 10 minutes. Add the heavy cream and cooked chicken tikka pieces. Simmer for an additional 5-10 minutes, stirring occasionally.\n",
      "\n",
      "5. Serve the Chicken Tikka Masala over steamed rice, garnished with fresh cilantro. Enjoy your delicious homemade Indian meal!\n",
      "\n",
      "Feel free to adjust the spice levels to suit your taste preferences. Enjoy your culinary journey into the flavors of India!For a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based alternative such as tofu or paneer. Here's how you can prepare these alternatives:\n",
      "\n",
      "1. **Tofu**: \n",
      "   - Use firm or extra firm tofu for this recipe.\n",
      "   - Drain the tofu and pat it dry with paper towels to remove excess moisture.\n",
      "   - Cut the tofu into bite-sized cubes and follow the marinade instructions as you would with the chicken. Tofu absorbs flavors well, so marinating it for a good amount of time will enhance its taste.\n",
      "   - Instead of baking, you can pan-fry the marinated tofu in a bit of oil until it's golden brown and slightly crispy.\n",
      "\n",
      "2. **Paneer**:\n",
      "   - Paneer is a type of Indian cheese that holds its shape well when cooked.\n",
      "   - Cut the paneer into cubes and follow the marinade instructions for the chicken.\n",
      "   - You can either bake the marinated paneer cubes in the oven or pan-fry them until they develop a golden crust.\n",
      "\n",
      "By using tofu or paneer as a substitute for chicken, you can still enjoy the rich flavors of Chicken Tikka Masala in a vegetarian-friendly way. Enjoy your meatless culinary adventure into Indian cuisine!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"For a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based alternative such as tofu or paneer. Here's how you can prepare these alternatives:\\n\\n1. **Tofu**: \\n   - Use firm or extra firm tofu for this recipe.\\n   - Drain the tofu and pat it dry with paper towels to remove excess moisture.\\n   - Cut the tofu into bite-sized cubes and follow the marinade instructions as you would with the chicken. Tofu absorbs flavors well, so marinating it for a good amount of time will enhance its taste.\\n   - Instead of baking, you can pan-fry the marinated tofu in a bit of oil until it's golden brown and slightly crispy.\\n\\n2. **Paneer**:\\n   - Paneer is a type of Indian cheese that holds its shape well when cooked.\\n   - Cut the paneer into cubes and follow the marinade instructions for the chicken.\\n   - You can either bake the marinated paneer cubes in the oven or pan-fry them until they develop a golden crust.\\n\\nBy using tofu or paneer as a substitute for chicken, you can still enjoy the rich flavors of Chicken Tikka Masala in a vegetarian-friendly way. Enjoy your meatless culinary adventure into Indian cuisine!\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "##\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "##\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "##\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\"cuisine\": \"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae697c0",
   "metadata": {},
   "source": [
    "### Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870d5610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event-driven, fast,\n",
      "JavaScript on server-side,\n",
      "Node.js, we code.이 해구는 5-7-5 소절 구조를 따르고 있습니다. 시인은 \"이벤트 중심, 빠른,\" \"서버 측 자바스크립트,\" \"노드.js, 우리는 코딩\"이라는 문장을 통해 Node.js의 특징을 강조하고 있습니다. \n",
      "\n",
      "이 해구는 기술적인 주제를 다루고 있으며, 자바스크립트를 사용하여 서버 측 프로그래밍을 할 수 있는 Node.js의 특징을 강조하고 있습니다. \"이벤트 중심\"과 \"빠른\"이라는 단어는 Node.js의 비동기적인 특성과 높은 성능을 나타내며, \"우리는 코딩\"이라는 문구는 개발자들이 Node.js를 사용하여 코딩하는 경험을 강조하고 있습니다. \n",
      "\n",
      "이 해구는 기술적인 주제를 다루고 있지만, 간결하고 명료한 표현을 통해 Node.js의 장점을 강조하고 있습니다. 이를 통해 기술적인 주제를 다루면서도 시적인 감성을 담아내고 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='이 해구는 5-7-5 소절 구조를 따르고 있습니다. 시인은 \"이벤트 중심, 빠른,\" \"서버 측 자바스크립트,\" \"노드.js, 우리는 코딩\"이라는 문장을 통해 Node.js의 특징을 강조하고 있습니다. \\n\\n이 해구는 기술적인 주제를 다루고 있으며, 자바스크립트를 사용하여 서버 측 프로그래밍을 할 수 있는 Node.js의 특징을 강조하고 있습니다. \"이벤트 중심\"과 \"빠른\"이라는 단어는 Node.js의 비동기적인 특성과 높은 성능을 나타내며, \"우리는 코딩\"이라는 문구는 개발자들이 Node.js를 사용하여 코딩하는 경험을 강조하고 있습니다. \\n\\n이 해구는 기술적인 주제를 다루고 있지만, 간결하고 명료한 표현을 통해 Node.js의 장점을 강조하고 있습니다. 이를 통해 기술적인 주제를 다루면서도 시적인 감성을 담아내고 있습니다.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "writing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are specialized in writing haikus about programming languages. Always generate responses in the form of a haiku (5-7-5 syllable structure) and ensure each haiku centers around themes of programming, coding languages, or software development. Be concise, creative, and poetic.\"),\n",
    "    (\"human\", \"{language}\"),\n",
    "])\n",
    "\n",
    "writing_chain = writing_prompt | chat \n",
    "\n",
    "reading_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are specialized in explaining haikus. When given a haiku, analyze its structure (syllable pattern, imagery, seasonal or thematic elements) and explain its meaning in a clear, thoughtful way in Korean. Focus on uncovering the poetic devices, cultural context, and emotional nuance. Be concise, insightful, and accessible to readers.\"),\n",
    "    (\"human\", \"{haiku}\"),\n",
    "])\n",
    "\n",
    "reading_chain = reading_prompt | chat\n",
    "\n",
    "final_chain = {\"haiku\": writing_chain} | reading_chain\n",
    "\n",
    "final_chain.invoke({\"language\": \"nodejs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf8ae6",
   "metadata": {},
   "source": [
    "### Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1713d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='🏠💰🔪'\n",
      "content='🚢💔🎶'\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"Top Gun\",\n",
    "        \"answer\": \"\"\"\n",
    "        🛩️👨‍✈️🔥\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"The Godfather\",\n",
    "        \"answer\": \"\"\"\n",
    "        👨‍👨‍👦🔫🍝\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{movie}\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie expert who provides three emojis to represent the movie.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{movie}?\"),\n",
    "])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert who provides three emojis to represent the movie.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"Parasite\")\n",
    "\n",
    "invoke_chain(\"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7867aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The movie you asked about first is \"Parasite.\"'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is the movie I asked first?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae29432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gwangwoopark/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gwangwoopark/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='According to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'\n",
      "content='He wrote \"2+2=5\" in the dust on the table.'\n",
      "content='Julia is a character in the text who was involved with the protagonist, Winston, in a forbidden relationship.'\n",
      "content=\"The first question you asked was about Aaronson's guilt.\"\n"
     ]
    }
   ],
   "source": [
    "# Assignment 4\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "def load_memory(_):\n",
    "    x = memory.load_memory_variables({})\n",
    "    return x[\"history\"]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"files/document.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer questions using only the following context and conversation history. If you don't know the answer, just say so. Don't make up an answer:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    { \n",
    "        \"context\": retriever, \n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": RunnableLambda(load_memory),\n",
    "    } \n",
    "    | prompt \n",
    "    | llm\n",
    ")\n",
    "    \n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"Is Aaronson guilty?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")\n",
    "invoke_chain(\"What is the first question I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5cf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
